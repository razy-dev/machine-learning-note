:rootdir: ..
:srcpath: /linear_regression
include::{rootdir}/adoc/toc.adoc[]

= Linear Regression using numpy

[NOTE]
====
주어진 `x` 와 `y` 의 관계를 제일 잘 설명한 하나의 선형(직선)함수 찾는 것
====

[ xref:{sourcedir}/lr_numpy.py[View Source] ]

== ABC
=== Dataset
```python
include::{sourcedir}/lr_numpy.py[tag=dataset]
```

=== Hypothesis(가설)
====
stem:[\hat{y} = wx + b]
====

.Hypothesis Function
```python
include::{sourcedir}/lr_numpy.py[tag=hypothesis]
```

=== Loss(Error) & Cost
Mean Squared Error(MSE: 평균제곱오차)
====
stem:[
\begin{align}
loss &= y_i - \hat{y_i} \\
cost &= \frac 1 n \sum_{i}^{n} loss^2 \\
     &= \frac 1 n \sum_{i}^{n} (y_i - \hat{y_i})^2 \\
     &= \frac 1 n \sum_{i}^{n} (y_i - (wx_i + b))^2 \\
\end{align}
]
====
.Cost Function
```python
include::{sourcedir}/lr_numpy.py[tag=cost]
```

=== Optimize

====
stem:[
\begin{align}
    \frac \partial{\partial w} cost(w)
    &= \frac \partial{\partial w} (\frac 1 n \sum_{i}^{n} (y_i - (wx_i + b))^2 ) \\
    &= \frac 1 n \sum_{i}^{n}
\end{align}
]
====
```python
include::{sourcedir}/lr_numpy.py[tag=dw]
```

```python
include::{sourcedir}/lr_numpy.py[tag=db]
```

```python
include::{sourcedir}/lr_numpy.py[tag=training]
```