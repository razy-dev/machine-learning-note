{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "torch.manual_seed(1)  # 난수 고정\n",
    "torch.set_printoptions(threshold=10, linewidth=128)  # for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.]],\n",
      "\n",
      "        [[2.],\n",
      "         [3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.],\n",
      "         [5.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.],\n",
      "         [6.],\n",
      "         [7.]],\n",
      "\n",
      "        [[6.],\n",
      "         [7.],\n",
      "         [8.]],\n",
      "\n",
      "        [[7.],\n",
      "         [8.],\n",
      "         [9.]]]) tensor([[ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "tensor([[[11.],\n",
      "         [12.],\n",
      "         [13.]],\n",
      "\n",
      "        [[12.],\n",
      "         [13.],\n",
      "         [14.]],\n",
      "\n",
      "        [[13.],\n",
      "         [14.],\n",
      "         [15.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[15.],\n",
      "         [16.],\n",
      "         [17.]],\n",
      "\n",
      "        [[16.],\n",
      "         [17.],\n",
      "         [18.]],\n",
      "\n",
      "        [[17.],\n",
      "         [18.],\n",
      "         [19.]]]) tensor([[14.],\n",
      "        [15.],\n",
      "        [16.],\n",
      "        [17.],\n",
      "        [18.],\n",
      "        [19.],\n",
      "        [20.]])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "time_steps = 3\n",
    "\n",
    "\n",
    "def build_dataset(data, time_steps: int = 3):\n",
    "    x, y = [], []\n",
    "    for i in range(time_steps, len(data)):\n",
    "        x.append(data[i - time_steps:i])\n",
    "        y.append(data[i])\n",
    "    return torch.FloatTensor(np.array(x)).unsqueeze(dim=2), torch.FloatTensor(np.array(y)).unsqueeze(dim=1)\n",
    "\n",
    "\n",
    "x_train, y_train = build_dataset(data=np.linspace(1, 10, 10, dtype=float))\n",
    "print(x_train, y_train)\n",
    "\n",
    "x_test, y_test = build_dataset(data=np.linspace(11, 20, 10, dtype=float))\n",
    "print(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6429], grad_fn=<SliceBackward0>) tensor([10.]) tensor(69.8413, grad_fn=<MseLossBackward0>)\n",
      "tensor([2.7217], grad_fn=<SliceBackward0>) tensor([10.]) tensor(52.9735, grad_fn=<MseLossBackward0>)\n",
      "tensor([3.5813], grad_fn=<SliceBackward0>) tensor([10.]) tensor(41.1998, grad_fn=<MseLossBackward0>)\n",
      "tensor([4.2953], grad_fn=<SliceBackward0>) tensor([10.]) tensor(32.5436, grad_fn=<MseLossBackward0>)\n",
      "tensor([4.9774], grad_fn=<SliceBackward0>) tensor([10.]) tensor(25.2269, grad_fn=<MseLossBackward0>)\n",
      "tensor([5.7191], grad_fn=<SliceBackward0>) tensor([10.]) tensor(18.3259, grad_fn=<MseLossBackward0>)\n",
      "tensor([6.5146], grad_fn=<SliceBackward0>) tensor([10.]) tensor(12.1477, grad_fn=<MseLossBackward0>)\n",
      "tensor([7.3692], grad_fn=<SliceBackward0>) tensor([10.]) tensor(6.9212, grad_fn=<MseLossBackward0>)\n",
      "tensor([8.2853], grad_fn=<SliceBackward0>) tensor([10.]) tensor(2.9402, grad_fn=<MseLossBackward0>)\n",
      "tensor([9.2177], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.6121, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.0134], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.4461], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.1990, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.4546], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.2405], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.0303], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
      "tensor([9.9238], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "tensor([9.9173], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "tensor([9.9642], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.0152], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "tensor([10.0418], grad_fn=<SliceBackward0>) tensor([10.]) tensor(0.0017, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.RNN(input_size=1, hidden_size=5, num_layers=1, nonlinearity='relu')\n",
    "criterion = nn.MSELoss()  # nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 0.01)\n",
    "for e in range(20):\n",
    "    for i, x in enumerate(x_train):\n",
    "        o, _ = model(x)\n",
    "        z = o[-1, -1:]\n",
    "        cost = criterion(z, y_train[i])\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    print(z, y_train[i], cost)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.],\n",
      "        [12.],\n",
      "        [13.]]) tensor([14.0702]) tensor([14.]) tensor([14.])\n",
      "tensor([[12.],\n",
      "        [13.],\n",
      "        [14.]]) tensor([15.0773]) tensor([15.]) tensor([15.])\n",
      "tensor([[13.],\n",
      "        [14.],\n",
      "        [15.]]) tensor([16.0844]) tensor([16.]) tensor([16.])\n",
      "tensor([[14.],\n",
      "        [15.],\n",
      "        [16.]]) tensor([17.0915]) tensor([17.]) tensor([17.])\n",
      "tensor([[15.],\n",
      "        [16.],\n",
      "        [17.]]) tensor([18.0986]) tensor([18.]) tensor([18.])\n",
      "tensor([[16.],\n",
      "        [17.],\n",
      "        [18.]]) tensor([19.1056]) tensor([19.]) tensor([19.])\n",
      "tensor([[17.],\n",
      "        [18.],\n",
      "        [19.]]) tensor([20.1127]) tensor([20.]) tensor([20.])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, x in enumerate(x_test):\n",
    "        o, _ = model(x)\n",
    "        z = o[-1, -1:]\n",
    "        print(x, z, z.round(), y_test[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}