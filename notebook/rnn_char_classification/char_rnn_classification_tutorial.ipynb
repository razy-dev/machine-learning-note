{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "문자 단위 RNN으로 이름 분류하기  \n",
    "*********************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
    "  **번역**: `황성수 <https://github.com/adonisues>`_\n",
    "\n",
    "\n",
    "단어를 분류하기 위해 기본적인 문자 단위 RNN을 만들고 훈련 할 것입니다. 문자 단위 RNN은 문자의 연속을 읽어 들여서 각 단계의 예측과 \"hidden state\" 출력하고 다음 단계에 이전 hidden state를 전달합니다. 즉 단어가 속한 클래스 같은 출력을 최종 예측으로 선택합니다.\n",
    "\n",
    "특히, 18개 언어로 된 수천 개의 성(姓)을 훈련시키고, 철자에 따라 이름이 어떤 언어인지 예측합니다:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hinton\n",
    "    (-0.47) Scottish\n",
    "    (-1.52) English\n",
    "    (-3.57) Irish\n",
    "\n",
    "    $ python predict.py Schmidhuber\n",
    "    (-0.19) German\n",
    "    (-2.48) Czech\n",
    "    (-2.68) Dutch\n",
    "\n",
    "\n",
    "**추천 자료:**\n",
    "\n",
    "최소한 Pytorch를 설치했고, Python을 알고, Tensor를 이해한다고 가정합니다.:\n",
    "\n",
    "-  http://pytorch.org/ 설치 안내를 위한 자료 \n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` 일반적인 PyTorch 시작을 위한 자료\n",
    "-  :doc:`/beginner/pytorch_with_examples` 넓고 깊은 통찰을 위한 자료\n",
    "-  :doc:`/beginner/former_torchies_tutorial` 이전 Lua Torch 사용자를 위한 자료\n",
    "\n",
    "RNN과 그 작동 방식을 아는 것 또한 유용합니다.:\n",
    "\n",
    "-  `The Unreasonable Effectiveness of Recurrent Neural\n",
    "   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n",
    "   실생활 예들을 보여 줍니다 \n",
    "-  `Understanding LSTM\n",
    "   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n",
    "   특히 LSTM에 관한 것이지만 일반적인 RNN에 대한 정보입니다. \n",
    "\n",
    "\n",
    "데이터 준비하기\n",
    "==================\n",
    "\n",
    ".. NOTE::\n",
    "   `여기 <https://download.pytorch.org/tutorial/data.zip>`__ 에서 데이터를 다운 받고,\n",
    "   현재 디렉토리에 압축을 푸십시오.\n",
    "\n",
    "\n",
    "\n",
    "``data/names`` 디렉토리에는 \"[Language].txt\" 라는 18 개의 텍스트 파일이 포함되어 있습니다. 각 파일에는 한 줄에 하나의 이름이 포함되어 있으며 대부분 로마자로 표시되어 있습니다 (그러나, 유니 코드에서 ASCII로 변환해야 함).\n",
    "\n",
    "언어 별 이름 목록 사전이 ``{language : [names ...]}`` 로 끝날 것입니다. 일반 변수 \"category\" 와 \"line\" (이 경우 언어와 이름 용)은 이후의 확장성을 위해 사용됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Czech.txt', 'data/names/German.txt', 'data/names/Arabic.txt', 'data/names/Japanese.txt', 'data/names/Chinese.txt', 'data/names/Vietnamese.txt', 'data/names/Russian.txt', 'data/names/French.txt', 'data/names/Irish.txt', 'data/names/English.txt', 'data/names/Spanish.txt', 'data/names/Greek.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Scottish.txt', 'data/names/Dutch.txt', 'data/names/Korean.txt', 'data/names/Polish.txt']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import os\n",
    "from io import open\n",
    "import glob\n",
    "\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "\n",
    "print(findFiles('data/names/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "# 유니 코드 문자열을 일반 ASCII로 변환하십시오. http://stackoverflow.com/a/518232/2809427 에 감사드립니다.\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# 언어별 이름 목록인 category_lines 사전을 만드십시오.\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "\n",
    "# 파일을 읽고 라인으로 분리하십시오\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이제 각 카테고리(언어)를 줄(이름) 목록에 매핑하는 사전인 \n",
    "``category_lines`` 가 있습니다. 또한 나중에 참조 할 수 있도록 \n",
    "``all_categories`` (언어 목록)와 ``n_categories`` 를 추적했습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이름을 Tensor 로 변경\n",
    "--------------------------\n",
    "\n",
    "이제는 모든 이름을 체계화 했으므로 이를 활용하기 위해 Tensor로 \n",
    "전환해야 합니다.\n",
    "\n",
    "하나의 문자를 표현하기 위해, 크기가 ``<1 x n_letters>`` 인 \n",
    "\"one-hot vector\" 를 사용합니다. one-hot 벡터는 현재 문자의 \n",
    "주소에만 1을 값을 가지고 그외에 나머지는 0으로 채워진다. \n",
    "예시 `` \"b\"= <0 1 0 0 0 ...> `` .\n",
    "\n",
    "단어를 만들기 위해 그 묶음을 2 차원 행렬 \n",
    "``<line_length x 1 x n_letters>`` 에 결합시킵니다.\n",
    "\n",
    "이 추가 1 차원은 PyTorch가 모든 것이 뱃치(batch)에 있다고 가정하기 \n",
    "때문에 발생합니다. 여기서는 뱃치 크기 1을 사용하고 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# all_letters 로 문자의 주소 찾기, 예시 \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "\n",
    "# 검증을 위해서 한 문자를 <1 x n_letters> Tensor로 변환하기\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# 한 줄(이름)을  <line_length x 1 x n_letters>,\n",
    "# 또는 문자 벡터의 어레이로 변경하기\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "네트워크 생성\n",
    "====================\n",
    "\n",
    "Autograd 전에, Torch에서 RNN(recurrent neural network) 생성에는 \n",
    "여러 타임 스텝에서 Layer의 파라미터를 복제하는 작업을 포함합니다.\n",
    "이제 Layer는 그래프 자체에서 완전히 처리되는 Hidden State와 \n",
    "Gradient를 가지게 됩니다. 즉, feed-forward layer 같은 매우 \"순수한\" \n",
    "방법으로 RNN을 구현할 수 있습니다.\n",
    "\n",
    "이 RNN 모듈 (대부분 `Torch 사용자를 위한 PyTorch 튜토리얼\n",
    "<http://pytorch.org/tutorials/beginner/former_torchies/\n",
    "nn_tutorial.html#example-2-recurrent-net>`__ 에서 복사). \n",
    "은 input 및 hidden state에서 작동하는 2개의 선형 레이어이며, \n",
    "출력 후에 LogSoftmax 레이어가 있습니다.\n",
    "\n",
    ".. figure:: https://i.imgur.com/Z2xbySO.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이 네트워크의 한 단계를 실행하려면 입력(현재 문자의 Tensor)과 \n",
    "이전의 hidden state (처음에는 0으로 초기화)를 전달해야 합니다.\n",
    "출력(각 언어의 확률)과 다음 hidden state (다음 단계를 위해 유지)를 \n",
    "돌려 받습니다.\n",
    "\n",
    "PyTorch 모듈은 Tensors에서 바로 작동하는 대신에 Variables에서 \n",
    "작동한다는 것을 기억하십시오.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input = Variable(letterToTensor('A'))\n",
    "hidden = Variable(torch.zeros(1, n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "효율성을 위해서 매 단계마다 새로운 Tensor를 만들고 싶지 않기 때문에\n",
    "``letterToTensor`` 대신 ``lineToTensor`` 를 잘라서 사용할 \n",
    "것입니다. 이것은 Tensor의 사전 연산(pre-computing) 뱃치에 의해 \n",
    "더욱 최적화 될 수 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0053, -2.7989, -2.8531, -2.8377, -2.8676, -2.9773, -2.7874, -2.8141,\n",
      "         -2.9755, -2.8387, -2.9845, -2.9853, -2.9678, -2.8342, -2.8267, -2.8906,\n",
      "         -2.8738, -2.9557]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = Variable(lineToTensor('Albert'))\n",
    "hidden = Variable(torch.zeros(1, n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "보시다시피 출력은 ``<1 x n_categories>`` Tensor이고, 모든 항목은 \n",
    "해당 카테고리의 우도(likelihood) 입니다 (더 높은 것이 더 가능성 높음).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "학습\n",
    "========\n",
    "학습 준비\n",
    "----------------------\n",
    "\n",
    "학습으로 들어가기 전에 몇몇 도움되는 함수를 만들어야합니다. 첫째는\n",
    "네트워크의 알고 있는 각 카테고리의 우도로 출력을 해석하기 입니다.\n",
    "가장 큰 값의 주소를 알기 위해서 ``Tensor.topk`` 를 쓸 수 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Russian', tensor(6))\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1)  # Tensor out of Variable with .data\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "또한 학습 예시(이름과 언어)를 얻는 빠른 방법을 원할 것입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = French / line = Michel\n",
      "category = Scottish / line = Lindsay\n",
      "category = Portuguese / line = Costa\n",
      "category = Russian / line = Robakidze\n",
      "category = Czech / line = Dana\n",
      "category = Dutch / line = Arendonk\n",
      "category = Scottish / line = Boyle\n",
      "category = Irish / line = Cennetig\n",
      "category = Korean / line = Shin\n",
      "category = English / line = Twiggs\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    line_tensor = Variable(lineToTensor(line))\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "네트워크 학습\n",
    "--------------------\n",
    "\n",
    "이제 이 네트워크를 훈련하는 데 필요한 모든 예시를 보여주고 추측을 \n",
    "하고, 만일 잘못되었다면 말해줍니다.\n",
    "\n",
    "RNN의 마지막 레이어가 ``nn.LogSoftmax`` 이므로 손실 함수로 \n",
    "``nn.NLLLoss`` 가 적합합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "학습의 각 루프는 다음을 실행 합니다.:\n",
    "\n",
    "-  입력과 목표 tensor 생성\n",
    "-  0 로 초기화된 hidden state 생성 \n",
    "-  각 문자를 읽기 \n",
    "\n",
    "   -  다음 문자를 위한 hidden state 유지\n",
    "\n",
    "-  목표와 출력 비교\n",
    "-  역전파\n",
    "-  출려과 손실 리턴\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005  # 이것을 너무 높게 설정하면 폭발할 수 있고 너무 낮으면 학습이 되지 않을 수 있습니다.\n",
    "\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # learning rate를 곱한 파리미터의 경사도를 파리미터 값에 더합니다.\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이제 예제를 사용하여 실행해야합니다. ``train`` 함수가 출력과 손실을 \n",
    "반환하기 때문에 추측을 출력하고 도식화를 위한 손실을 추적 할 수 \n",
    "있습니다. 1000개의 예제가 있기 때문에 모든 ``print_every`` 예제만 \n",
    "출력하고 손실의 평균을 얻습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/wdyskqm96nv4msmwh8bfw7w80000gp/T/ipykernel_55172/1126802071.py:17: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(-learning_rate, p.grad.data)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [14], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_iters \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     24\u001B[0m     category, line, category_tensor, line_tensor \u001B[38;5;241m=\u001B[39m randomTrainingExample()\n\u001B[0;32m---> 25\u001B[0m     output, loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcategory_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     current_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# iter 숫자, 손실, 이름, 추측 출력\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [13], line 19\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(category_tensor, line_tensor)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m rnn\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[1;32m     17\u001B[0m     p\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39madd_(\u001B[38;5;241m-\u001B[39mlearning_rate, p\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mdata)\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output, \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "# 도식화를 위한 소실 추적\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # iter 숫자, 손실, 이름, 추측 출력\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print(\n",
    "            '%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # 현재 평균 손실을 손실 리스트에 추가\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "결과 도식화\n",
    "--------------------\n",
    "\n",
    "``all_losses`` 를 이용한 역사적인 손실 도식화는 \n",
    "네트워크의 학습을 보여준다\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "결과 평가\n",
    "======================\n",
    "\n",
    "네트워크가 다른 카테고리에서 얼마나 잘 작동하는지 보려면 \n",
    "네트워크에서 추측한 언어(행)와 실제 언어(행)를 나타내는 \n",
    "혼란 행열(confusion matrix)을 만듭니다. 혼란 행렬을 계산하기 위해 \n",
    "``evaluate()`` 로 많은 수의 샘플을 네트워크에 실행합니다. \n",
    "``evaluate()`` 은 ``train ()`` 과 역전파를 빼면 동일합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 혼란 행렬에서 정확한 추측을 추적\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "\n",
    "# 주어진 라인의 출력 반환\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# 올바르게 추측 된 예시와 기록을 살펴보십시오.\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# 모든 행을 합계로 나눔으로써 정규화하십시오.\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# 도식 설정\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# 축 설정\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# 모든 tick에서 강제로 레이블 지정 \n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "주축에서 벗어난 밝은 점을 선택하여 잘못 추측한 언어를 표시 \n",
    "할 수 있습니다. 예를 들어 한국어는 중국어로 이탈리아어로 스페인어로.\n",
    "그리스어는 매우 잘되는 것으로 영어는 매우 나쁜것으로 보입니다.\n",
    "(아마도 다른 언어들과 중첩되기 때문에)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "사용자 입력으로 실행\n",
    "---------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    output = evaluate(Variable(lineToTensor(input_line)))\n",
    "\n",
    "    # 최고 N 카테고리 얻기\n",
    "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i]\n",
    "        category_index = topi[0][i]\n",
    "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "        predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`실용 PyTorch 저장소\n",
    "<https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n",
    "의 최종 버전 스크립트는 위 코드를 몇개의 파일로 분할했습니다.:\n",
    "\n",
    "-  ``data.py`` (파일 읽기)\n",
    "-  ``model.py`` (RNN 정의)\n",
    "-  ``train.py`` (학습 실행)\n",
    "-  ``predict.py`` (커멘드 라인 인자로 ``predict()`` 실행)\n",
    "-  ``server.py`` (bottle.py를 사용하여 JSON API로 예측 제공)\n",
    "\n",
    "학습과 네트워크 저장을 위해 ``train.py`` 실행.\n",
    "\n",
    "이름으로 예측을 보기 위해 ``predict.py`` 실행:\n",
    "\n",
    "::\n",
    "\n",
    "    $ python predict.py Hazaki\n",
    "    (-0.42) Japanese\n",
    "    (-1.39) Polish\n",
    "    (-3.51) Czech\n",
    "\n",
    "``server.py`` 를 실행하고 예측의 JSON 출력을 얻기 위해 \n",
    "http://localhost:5533/Yourname 방문.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "연습\n",
    "=========\n",
    "\n",
    "-  \"line -> category\" 의 다른 데이터 집합으로 시도해보십시오, 예를 들어:\n",
    "\n",
    "   -  단어 -> 언어\n",
    "   -  이름 -> 성별\n",
    "   -  캐릭터 이름 -> 작가\n",
    "   -  페이지 제목 -> 블로그 또는 서브레딧\n",
    "\n",
    "-  더 크고 더 나은 모양의 네트워크로 더 나은 결과를 얻으십시오.\n",
    "\n",
    "   -  더많은 선형 layer 추가해 보십시오\n",
    "   -  ``nn.LSTM`` 과 ``nn.GRU`` layer 추가해 보십시오\n",
    "   -  여러 개의 이런 RNN을 상위 수준 네트워크로 결합해 보십시오\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}