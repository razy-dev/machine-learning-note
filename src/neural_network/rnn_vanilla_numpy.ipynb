{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# https://wikidocs.net/60690\n",
    "# https://velog.io/@wltn39/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D-RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "timesteps = 10  # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
    "input_size = 4  # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
    "hidden_size = 8  # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
    "hidden_state_t = np.zeros((hidden_size,))  # 초기 은닉 상태는 0(벡터)로 초기화, 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "Wx = np.random.random((hidden_size, input_size))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
    "Wh = np.random.random((hidden_size, hidden_size))  # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
    "b = np.random.random((hidden_size,))  # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.77491295 0.89826424 0.87513684 0.448048   0.38403364 0.74659069\n",
      "  0.37373024 0.48450157]\n",
      " [0.99989218 0.99975494 0.99829018 0.99865714 0.99912275 0.99811379\n",
      "  0.98921628 0.99958908]\n",
      " [0.99999748 0.99999598 0.99981824 0.99997453 0.99997388 0.9998656\n",
      "  0.9988667  0.99999074]\n",
      " [0.99999719 0.99999857 0.99991379 0.99998503 0.99997746 0.99989754\n",
      "  0.99902792 0.99998404]\n",
      " [0.99999707 0.99999428 0.99977178 0.99996807 0.99996875 0.99987882\n",
      "  0.99902742 0.99999137]\n",
      " [0.99999788 0.99999742 0.99993212 0.99997914 0.99998295 0.99992823\n",
      "  0.99954852 0.99999352]\n",
      " [0.99999908 0.99999957 0.99994018 0.9999945  0.99998594 0.99991434\n",
      "  0.99899202 0.99999273]\n",
      " [0.99999724 0.99999727 0.99981483 0.9999797  0.99997123 0.99985496\n",
      "  0.99852378 0.99998644]\n",
      " [0.99999958 0.99999976 0.99997996 0.99999645 0.99999286 0.99996262\n",
      "  0.99969335 0.99999765]\n",
      " [0.9999959  0.99999586 0.99983319 0.99997011 0.99997216 0.99982114\n",
      "  0.99843693 0.99998055]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.random((timesteps, input_size))  # 입력에 해당되는 2D 텐서\n",
    "total_hidden_states = []\n",
    "\n",
    "# 메모리 셀 동작\n",
    "for input_t in inputs:  # 각 시점에 따라서 입력값이 입력됨.\n",
    "    output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b)  # Wx * Xt + Wh * Ht-1 + b(bias)\n",
    "    total_hidden_states.append(list(output_t))  # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
    "    print(np.shape(total_hidden_states))  # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
    "    hidden_state_t = output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
    "# 출력 시 값을 깔끔하게 해준다.\n",
    "\n",
    "print(total_hidden_states)  # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}